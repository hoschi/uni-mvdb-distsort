<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html dir="ltr">
  <head>
	  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
	  <link rel="stylesheet" type="text/css" href="http://ajax.googleapis.com/ajax/libs/dojo/1.5/dijit/themes/claro/claro.css" />
	  <link rel="stylesheet" type="text/css" href="http://ajax.googleapis.com/ajax/libs/dojo/1.5/dojox/grid/resources/Grid.css" />
	  <link rel="stylesheet" type="text/css" href="http://ajax.googleapis.com/ajax/libs/dojo/1.5/dojox/grid/resources/claroGrid.css" />
	  <style type="text/css">
		body, html 
		{
		  height:100%;
		  width:100%;
		}
	  </style>
	  <script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/dojo/1.5/dojo/dojo.xd.js"
			  djConfig="parseOnLoad: true, dojoCallbackUrl:'./blank.html'">
	  </script>
	  <script type="text/javascript" src="./sort.js">
	  </script>
	  <script type="text/javascript" src="./join.js">
	  </script>
	  <script type="text/javascript" src="./generated_toc.js">
	  </script>
  </head>

  
  <body class="claro">
    <div id="generated-toc"></div>
    <h1>Sortierung</h1>
	<p>
		Getestet wurde das Programm auf einem Quad Core mit 2600MHz pro Core
		und 8GB Arbeitsspeicher. Betriebssystem ist Debian Lenny amd64 mit
		modifiziertem XEN Kernel. Zeitliche Messungen sind in der JVM
		schwierig, durch die verwendete HotSpot Technologie. Das sieht man auch
		hier deutlich am "Knick" im ersten Diagramm. Eigentlich sollte die
		Kurve mehr oder weniger linear ansteigen.
	</p>
	<p>
		Das lokale Sortieren ist wesentlich schneller, unabhängig von der
		Datengröße die zu sortieren ist. Das liegt massiv daran, das durch RMI
		ein Overhead entsteht:
		<ul>
			<li>es müssen Listen umkopiert werden da keine Referenzen
			übertragen werden</li>
			<li>de-/seriealisieren der Daten</li>
			<li>TCP/IP zur Kommunikation</li>
		</ul>
		Das sortieren wird auch langsamer, umso kleiner die Blockgröße gewählt
		wird. Durch mehr Blöcke ensteht mehr Kommunikationsaufwand.
	</p>
	<p>
		Das der verteilte Distribution Sort Algorithmus ist, mit zunehmender
		Daten Größe, langsamer als der verteilte Merge Sort Algorithmus. Das
		liegt meiner Meinung daran das beim Distribution Sort ein zusäztlicher
		Lesezyklus vorhanden ist um die Grenzelemente auszulosen, sowie die
		Verwendung von Zufallszahlen. Ersteres macht sich natürlich bei großen
		Datenmengen stärker bemerkbar.
	</p>

	<h2>lokale Sortierung</h2>
		Wenn man mit der Maus über den Datenpunkt fährt, sieht man direkt den Wert.
	<div id="chart1"></div>

	<h2>Blockgröße = unendlich</h2>
		Legende:
		<ul>
			<li>grün = merge sort</li>
			<li>blau = distribution sort</li>
		</ul>
	<div id="chart2"></div>

	<h2>Blockgröße = 10000</h2>
	<div id="chart3"></div>

	<h2>Blockgröße = 1000</h2>
	<div id="chart4"></div>

	<h2>Blockgröße = 100</h2>
	<div id="chart5"></div>


	<h1>Joins</h1>
	<p>
		Auch hier sieht man wie oben das mehr Netzwerkverkehr zu längeren gesamt
		Laufzeiten führt, da die jeweiligen Diagramme korrelieren. Der "ship as a
		whole" Algorithmus verursacht am wenigesten Verkehr und ist der
		schnellste, wo gegen "fetch as needed" mit Abstand am langsamste ist.
	</p>
	
	<h2>Distributed Joins</h2>
		Legende:
		<ul>
			<li>grün = ship as a whole</li>
			<li>blau = semi join V1 (an Knoten R)</li>
			<li>gelb = semi join V2 (an Knoten S)</li>
			<li>magenta = semi join V3 (parallel)</li>
			<li>cyan = semi join V4 (sequentiell über Knoten S)</li>
		</ul>
	<div id="joinchartDistNetwork"></div>
	<div id="joinchartDistJoin"></div>
	<div id="joinchartDistAll"></div>

	<h2>Fetch As Needed Join</h2>
	<div id="joinchartFetchAsNeeded"></div>

  </body>
</html>
